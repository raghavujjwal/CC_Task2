{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3baa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fitz\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "from spacy.lang.en import English\n",
    "import re\n",
    "from sentence_transformers import util, SentenceTransformer\n",
    "from time import perf_counter as timer\n",
    "from textwrap import wrap\n",
    "import textwrap\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1368dbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = r\"C:\\Users\\ujjwal\\OneDrive\\Desktop\\Projects\\CC_Task2\\Engg_colleges.pdf\"\n",
    "def text_formatter(text: str) -> str:\n",
    "    cleaned_txt = text.replace(\"\\n\", \" \").strip()\n",
    "    return cleaned_txt\n",
    "def open_and_read_pdf(pdf_path: str) -> str:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    pages_and_texts = []\n",
    "    for page_number, page in tqdm(enumerate(doc), desc = \"Reading PDF\"):\n",
    "        text = page.get_text()\n",
    "        text = text_formatter(text)\n",
    "        pages_and_texts.append({\"page_number\": page_number, \"page_char_count\": len(text), \"page_word_count\": len(text.split(\" \")), \"page_sentence_count_raw\": len(text.split(\". \")), \"page_token_count\": len(text)/4, \"text\": text})\n",
    "\n",
    "    return pages_and_texts\n",
    "pages_and_texts = open_and_read_pdf(pdf_path)\n",
    "pages_and_texts[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01479dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c64053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "doc = nlp(\"This is s. This is d. This is sh.\")\n",
    "\n",
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae6ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in tqdm(pages_and_texts, desc = \"Extracting Sentences\"):\n",
    "    doc = nlp(item[\"text\"])\n",
    "    item[\"sentences\"] = [str(sentence) for sentence in doc.sents]\n",
    "    item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1219888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_sentences(pages_and_texts):\n",
    "    for item in tqdm(pages_and_texts, desc=\"Extracting Sentences\"):\n",
    "        doc = nlp(item[\"text\"])\n",
    "        item[\"sentences\"] = [str(sentence) for sentence in doc.sents]\n",
    "        item[\"sentence_chunks\"] = [item[\"sentences\"][i:i+10] for i in range(0, len(item[\"sentences\"]), 10)]\n",
    "    return pages_and_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e821b598",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.sample(pages_and_texts, k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabeda9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sentence_chunk_size = 10\n",
    "def split_list(input_list, slice_size = num_sentence_chunk_size):\n",
    "    return [input_list[i:1+slice_size] for i in range(0, len(input_list), slice_size)]\n",
    "\n",
    "test_list = list(range(25))\n",
    "split_list(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8047e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in tqdm(pages_and_texts, desc = \"Creating chunks\"):\n",
    "    item[\"sentence_chunks\"] = split_list(input_list = item[\"sentences\"])\n",
    "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33595860",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.sample(pages_and_texts, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d1ee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbebbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_and_chunks = []\n",
    "for item in tqdm(pages_and_texts, desc = \"Building final structure\"):\n",
    "    for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "        chunk_dict = {}\n",
    "        chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
    "        joined_sentence_chunk = \" \".join(sentence_chunk).replace(\" \", \" \").strip()\n",
    "        joined_sentence_chunk = re.sub(r\"\\.([A-Z])\", r\".\\1\", joined_sentence_chunk)\n",
    "        chunk_dict[\"chunk\"] = joined_sentence_chunk\n",
    "        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \") if word])\n",
    "       \n",
    "        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk)/4\n",
    "\n",
    "        pages_and_chunks.append(chunk_dict)\n",
    "\n",
    "len(pages_and_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbea343",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.sample(pages_and_chunks, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d48abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8d3381",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_token_length = 30\n",
    "chunks_df = pd.DataFrame(pages_and_chunks)\n",
    "for row in chunks_df[chunks_df[\"chunk_token_count\"] <= min_token_length].sample(5).iterrows():\n",
    "    print(f\"Chunk token count: {row[1][\"chunk_token_count\"]} | Text: {row[1][\"chunk\"]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30bd8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_and_chunks_min_token_len = chunks_df[chunks_df[\"chunk_token_count\"]>min_token_length].to_dict(orient = \"records\")\n",
    "pages_and_chunks_min_token_len[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5e9125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_chunks(pages_and_texts):\n",
    "    pages_and_chunks = []\n",
    "    for item in tqdm(pages_and_texts, desc=\"Building chunks\"):\n",
    "        for chunk in item[\"sentence_chunks\"]:\n",
    "            joined = \" \".join(chunk).strip()\n",
    "            if len(joined)/4 > 10:\n",
    "                pages_and_chunks.append({\n",
    "                    \"page_number\": item[\"page_number\"],\n",
    "                    \"chunk\": joined,\n",
    "                    \"embedding\": None\n",
    "                })\n",
    "    return pages_and_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208a7454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_chunks(pages_and_chunks):\n",
    "    model = SentenceTransformer(\"all-mpnet-base-v2\", device=\"cpu\")\n",
    "    for item in tqdm(pages_and_chunks, desc=\"Generating embeddings\"):\n",
    "        item[\"embedding\"] = model.encode(item[\"chunk\"])\n",
    "    return model, pages_and_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a1fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_preferences():\n",
    "    print(\" Hey there! Iâ€™m your college guide bot. Iâ€™ll help you shortlist the best-fit engineering colleges for you.\\n\")\n",
    "    print(\"Letâ€™s chat a bit so I can understand what you're looking for. Ready? Let's go!\\n\")\n",
    "\n",
    "    preferences = {}\n",
    "\n",
    "    preferences[\"general\"] = input(\" What are some things youâ€™re looking for in a college? (e.g., branch, location, campus life, research, etc.)\\n> \")\n",
    "\n",
    "    preferences[\"branch\"] = input(\"\\n Do you have a preferred engineering branch or field? (If not sure, just say that!)\\n> \")\n",
    "\n",
    "    preferences[\"location\"] = input(\"\\n Any preferred states or cities for college?\\n> \")\n",
    "\n",
    "    preferences[\"college_type\"] = input(\"\\n Do you prefer a government college (like NITs/IITs) or private universities â€” or are you open to both?\\n> \")\n",
    "\n",
    "    preferences[\"campus_life\"] = input(\"\\n How important is campus life (clubs, fests, student activities) for you?\\n> \")\n",
    "\n",
    "    preferences[\"academics_vs_fun\"] = input(\"\\n Would you like a college thatâ€™s more academically focused, fun/social, or a mix of both?\\n> \")\n",
    "\n",
    "    preferences[\"budget\"] = input(\"\\n Are there any budget or fee constraints I should know about?\\n> \")\n",
    "\n",
    "    preferences[\"extra_notes\"] = input(\"\\n Anything else you'd like me to keep in mind? (e.g., placements, internships, foreign exchange, etc.)\\n> \")\n",
    "\n",
    "    print(\"\\nThanks! Let me think for a moment... \\n\")\n",
    "\n",
    "    \n",
    "    preference_summary = (\n",
    "        f\"General preferences: {preferences['general']}\\n\"\n",
    "        f\"Preferred branch: {preferences['branch']}\\n\"\n",
    "        f\"Preferred location: {preferences['location']}\\n\"\n",
    "        f\"College type preference: {preferences['college_type']}\\n\"\n",
    "        f\"Campus life importance: {preferences['campus_life']}\\n\"\n",
    "        f\"Academic vs Fun balance: {preferences['academics_vs_fun']}\\n\"\n",
    "        f\"Budget/Fees: {preferences['budget']}\\n\"\n",
    "        f\"Additional notes: {preferences['extra_notes']}\"\n",
    "    )\n",
    "\n",
    "    return preferences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f069ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_pdf(pages_and_texts, chunk_size=500):\n",
    "    pages_and_chunks = []\n",
    "    for page in pages_and_texts:\n",
    "        text = page[\"text\"]\n",
    "        \n",
    "        chunks = wrap(text, chunk_size)\n",
    "        for chunk in chunks:\n",
    "            pages_and_chunks.append({\n",
    "                \"chunk\": chunk,\n",
    "                \"page_number\": page[\"page_number\"]\n",
    "            })\n",
    "    return pages_and_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76888d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, embedded_chunks = embed_chunks(pages_and_chunks)\n",
    "\n",
    "print(model)\n",
    "print(embedded_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f62bea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks_and_embeddings_df = pd.DataFrame(pages_and_chunks_min_token_len)\n",
    "text_chunks_and_embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee5bf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df_save_path = r\"C:\\Users\\ujjwal\\OneDrive\\Desktop\\Projects\\CC_Task2\\text_chunks_and_embeddings_df.csv\"\n",
    "text_chunks_and_embeddings_df.to_csv(embeddings_df_save_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9143765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_and_chunks[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf6dc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_wrapped(text, wrap_length = 50):\n",
    "    wrapped_text = textwrap.fill(text, wrap_length)\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12f09f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Programs offered at IIT Delhi\"\n",
    "print(f\"Query: {query}\")\n",
    "for score, idx in zip(top_results[0], top_results[1]):\n",
    "    print(f\"Score: {score:.4f}\")\n",
    "    print(\"Text:\")\n",
    "    print(pages_and_chunks[idx][\"chunk\"])\n",
    "    print(f\"Page number: {pages_and_chunks[idx]['page_number']}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a979d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(vector1, vector2):\n",
    "    return torch.dot(vector1, vector2)\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    dot_product = torch.dot(vector1, vector2)\n",
    "    norm_vector1 = torch.sqrt(torch.sum(vector1**2))\n",
    "    norm_vector2 = torch.sqrt(torch.sum(vector2**2))\n",
    "    return dot_product / (norm_vector1 * norm_vector2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbfc5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_sources(query, pages_and_chunks, model, number_to_return=5, print_time=True):\n",
    "    # Embed the query (which should be a string)\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "    start_time = timer()\n",
    "\n",
    "    # Get precomputed chunk embeddings\n",
    "    embeddings = [item[\"embedding\"] for item in pages_and_chunks]\n",
    "\n",
    "    # Compute similarity scores\n",
    "    dot_scores = util.dot_score(query_embedding, embeddings)[0]\n",
    "    end_time = timer()\n",
    "\n",
    "    if print_time:\n",
    "        print(f\"Retrieved in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    # Get top results\n",
    "    top_results = torch.topk(dot_scores, k=number_to_return)\n",
    "    return top_results.values, top_results.indices\n",
    "\n",
    "\n",
    "def print_top_results_and_scores(query: str, pages_and_chunks, model: SentenceTransformer, number_to_return: int = 5):\n",
    "    scores, indices = retrieve_sources(query, pages_and_chunks, model, number_to_return=number_to_return)\n",
    "    for score, idx in zip(scores, indices):\n",
    "        print(f\"Score: {score:.4f}\")  \n",
    "        print(\"Text:\")\n",
    "        print(pages_and_chunks[idx.item()][\"chunk\"])  \n",
    "        print(f\"Page number: {pages_and_chunks[idx.item()]['page_number']}\")\n",
    "        print(\"\\n\" + \"-\"*60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb3ec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"2+2 dual degree programs\"\n",
    "\n",
    "print_top_results_and_Scores(\n",
    "    query=query, \n",
    "    embeddings=embeddings, \n",
    "    pages_and_chunks=pages_and_chunks,\n",
    "    model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c792c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "genai.configure(api_key=\"AIzaSyDWUo-rusTBagnDnQi-GFSKwzQ1VKdV8iQ\")\n",
    "gemini_model = genai.GenerativeModel(\"gemini-2.5-pro-exp-03-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aac2efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_user_preferences():\n",
    "    print(\"Hey there! Iâ€™m your college guide bot. Iâ€™ll help you shortlist the best-fit engineering colleges for you.\\n\")\n",
    "    print(\"Letâ€™s chat a bit so I can understand what you're looking for. Ready? Let's go!\\n\")\n",
    "\n",
    "    preferences = {}\n",
    "\n",
    "    preferences[\"general\"] = input(\"What are some things youâ€™re looking for in a college? (e.g., branch, location, campus life, research, etc.)\\n> \")\n",
    "    preferences[\"branch\"] = input(\"\\nDo you have a preferred engineering branch or field? (If not sure, just say that!)\\n> \")\n",
    "    preferences[\"location\"] = input(\"\\nAny preferred states or cities for college?\\n> \")\n",
    "    preferences[\"college_type\"] = input(\"\\nDo you prefer a government college (like NITs/IITs) or private universities â€” or are you open to both?\\n> \")\n",
    "    preferences[\"campus_life\"] = input(\"\\nHow important is campus life (clubs, fests, student activities) for you?\\n> \")\n",
    "    preferences[\"academics_vs_fun\"] = input(\"\\nWould you like a college thatâ€™s more academically focused, fun/social, or a mix of both?\\n> \")\n",
    "    preferences[\"budget\"] = input(\"\\nAre there any budget or fee constraints I should know about?\\n> \")\n",
    "    preferences[\"extra_notes\"] = input(\"\\nAnything else you'd like me to keep in mind? (e.g., placements, internships, foreign exchange, etc.)\\n> \")\n",
    "\n",
    "    gave_exam = input(\"\\nHave you given any entrance exam yet? (yes/no)\\n> \").strip().lower()\n",
    "    if gave_exam == \"yes\":\n",
    "        preferences[\"gave_exam\"] = True\n",
    "        preferences[\"exam\"] = input(\"\\nWhich entrance exam did you give? (e.g., JEE Main, BITSAT, etc.)\\n> \")\n",
    "        preferences[\"score\"] = input(\"\\nWhat was your score or percentile?\\n> \")\n",
    "    else:\n",
    "        preferences[\"gave_exam\"] = False\n",
    "\n",
    "    print(\"\\nThanks! Let me think for a moment... \\n\")\n",
    "    return preferences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf79196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_response_with_gemini(preferences, top_chunks):\n",
    "    context = \"\\n\\n\".join([chunk[\"chunk\"] for chunk in top_chunks])\n",
    "    prompt = (\n",
    "        f\"You are a helpful college counselor.\\n\\n\"\n",
    "        f\"Student Preferences:\\n\"\n",
    "        f\"- Preferred Branch: {preferences['branch']}\\n\"\n",
    "        f\"- Location Preference: {preferences['location']}\\n\"\n",
    "        f\"- College Type: {preferences['college_type']}\\n\"\n",
    "        f\"- Campus Life Importance: {preferences['campus_life']}\\n\"\n",
    "        f\"- Academic vs Fun Preference: {preferences['academics_vs_fun']}\\n\"\n",
    "        f\"- Budget: {preferences['budget']}\\n\"\n",
    "        f\"- General Interests: {preferences['general']}\\n\"\n",
    "        f\"- Other Notes: {preferences['extra_notes']}\\n\\n\"\n",
    "        f\"Based on the official brochure below, strictly recommend up to 3 engineering colleges in India that are the best fit.\\n\\n\"\n",
    "        f\"--- Brochure Snippets ---\\n{context}\"\n",
    "    )\n",
    "\n",
    "    response = gemini_model.generate_content(prompt)\n",
    "    print(\"\\nðŸŽ“ Final Recommendations:\\n\")\n",
    "    print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7643e607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    pages = open_and_read_pdf(r\"C:\\Users\\ujjwal\\OneDrive\\Desktop\\Projects\\CC_Task2\\Engg_colleges.pdf\")\n",
    "    pages = chunk_sentences(pages)\n",
    "    pages_and_chunks = flatten_chunks(pages)\n",
    "    embedding_model, pages_and_chunks = embed_chunks(pages_and_chunks)\n",
    "\n",
    "    preferences = collect_user_preferences()\n",
    "    query = (\n",
    "    f\"{preferences['branch']} engineering programs \"\n",
    "    f\"in {preferences['location']} \"\n",
    "    f\"at {preferences['college_type']} colleges \"\n",
    "    f\"with focus on {preferences['general']} \"\n",
    "    f\"and a budget of {preferences['budget']}\"\n",
    ")\n",
    "\n",
    "    scores, indices = retrieve_sources(query, pages_and_chunks, embedding_model)\n",
    "    top_chunks = [pages_and_chunks[idx.item()] for idx in indices]\n",
    "\n",
    "    generate_final_response_with_gemini(preferences, top_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c93de5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
